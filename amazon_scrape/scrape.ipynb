{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from requestium import Session, Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "driver_path = ChromeDriverManager().install()\n",
    "s = Session(webdriver_path=driver_path)\n",
    "s.driver.implicitly_wait(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the website and clear the captcha\n",
    "\n",
    "s.driver.get(\"https://www.amazon.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.transfer_driver_cookies_to_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108\n"
     ]
    }
   ],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "def collect_asin_from_search_results():\n",
    "    asin_list = list()\n",
    "    while True:\n",
    "        records = s.driver.find_elements(By.XPATH, \"//div[@data-component-type='s-search-result']\")\n",
    "        asins = [record.get_attribute(\"data-asin\") for record in records]\n",
    "        asin_list.extend(asins)\n",
    "        next_page_link = s.driver.find_element(By.CSS_SELECTOR, \".s-pagination-next\")\n",
    "        if next_page_link.get_attribute(\"aria-disabled\") == \"true\":\n",
    "            break\n",
    "        next_page_link.click()\n",
    "        \n",
    "    return asin_list\n",
    "\n",
    "def get_seed_asins(query):\n",
    "    s.driver.get(\"https://www.amazon.com\")\n",
    "    search_box = s.driver.find_element(By.ID, \"twotabsearchtextbox\")\n",
    "    search_box.send_keys(query)\n",
    "    search_box.submit()\n",
    "    return collect_asin_from_search_results()\n",
    "\n",
    "asin_list = get_seed_asins(\"knitted weighted blanket\")\n",
    "print(len(asin_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = s.headers\n",
    "cookies = s.cookies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 104 products\n"
     ]
    }
   ],
   "source": [
    "import multiprocess as mp\n",
    "from pathlib import Path\n",
    "import requests\n",
    "from copy import deepcopy\n",
    "\n",
    "from urllib.parse import urljoin\n",
    "import lxml.etree as ET\n",
    "import re\n",
    "import inflection\n",
    "import json\n",
    "from itertools import chain\n",
    "\n",
    "\n",
    "html_dir = Path(\"./pages\")\n",
    "data_dir = Path(\"./data\")\n",
    "image_dir = Path(\"./images\")\n",
    "\n",
    "html_dir.mkdir(exist_ok=True)\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "image_dir.mkdir(exist_ok=True)\n",
    "\n",
    "def download_product_page(asin):\n",
    "    out_path = html_dir / f\"{asin}.html\"\n",
    "    if out_path.exists() and out_path.stat().st_size > 0:\n",
    "        return out_path\n",
    "    url = f\"https://www.amazon.com/dp/{asin}\"\n",
    "    response = requests.get(url, headers=headers, cookies=cookies)\n",
    "    try:\n",
    "        response.raise_for_status()\n",
    "        tree = ET.HTML(response.text)\n",
    "        captcha = tree.xpath('.//h4[contains(text(), \"Enter the characters you see below\")]')\n",
    "        if captcha:\n",
    "            print(f\"Encountered captcha for {url}\")\n",
    "            raise ValueError(\"Captcha encountered\")\n",
    "        out_path.write_text(response.text)\n",
    "        return out_path\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print(f\"Failed to download {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "product_base_url = \"https://www.amazon.com/dp/\"\n",
    "seller_id_re = re.compile(r\"seller=([^&]+)&\")\n",
    "\n",
    "\n",
    "def parse_product_details(page_el):\n",
    "    detail_rows = page_el.cssselect(\"table#productDetails_detailBullets_sections1 tr\")\n",
    "    output = dict()\n",
    "    for row in detail_rows:\n",
    "        key = row.cssselect(\"th\")[0].text.strip()\n",
    "        value = row.cssselect(\"td\")[0].text.strip()\n",
    "        output[inflection.underscore(key.replace(\" \", \"_\"))] = value\n",
    "    return output\n",
    "\n",
    "def parse_product_page(page_text):\n",
    "    tree = ET.HTML(page_text)\n",
    "    variant_el = tree.find(\".//form[@id='twister']\")\n",
    "    try:\n",
    "        variant_asins = [i for i in variant_el.xpath(\".//li[@data-csa-c-item-id]/@data-csa-c-item-id\") if i]\n",
    "    except AttributeError:\n",
    "        variant_asins = []\n",
    "    try:\n",
    "        cover_image_url = tree.xpath('.//img[@data-a-image-name=\"landingImage\"]/@src')[0]\n",
    "    except IndexError:\n",
    "        cover_image_url = None\n",
    "    try:\n",
    "        price_div = tree.cssselect('div#corePriceDisplay_desktop_feature_div span.aok-offscreen')[0]\n",
    "        price = \"\".join(price_div.itertext()).strip()\n",
    "    except IndexError:\n",
    "        price = None\n",
    "    try:\n",
    "        merchant_el = tree.cssselect(\"div#merchantInfoFeature_feature_div a#sellerProfileTriggerId\")[0]\n",
    "    except IndexError:\n",
    "        merchant_el = None\n",
    "    \n",
    "    return {\n",
    "        \"product_title\": tree.cssselect(\"span#productTitle\")[0].text.strip(),\n",
    "        \"product_details\": parse_product_details(tree),\n",
    "        \"variant_asins\": variant_asins,\n",
    "        \"cover_image\": urljoin(product_base_url, cover_image_url) if cover_image_url is not None else None,\n",
    "        \"price\": price,\n",
    "        \"merchant_name\": merchant_el.text if merchant_el is not None else None,\n",
    "        \"merchant_url\": urljoin(product_base_url, merchant_el.get(\"href\")) if merchant_el is not None else None,\n",
    "        \"seller_id\": seller_id_re.search(merchant_el.get(\"href\")).group(1) if merchant_el is not None else None\n",
    "    }\n",
    "\n",
    "\n",
    "def parse_path(path):\n",
    "    data_path = data_dir / f\"{path.stem}.json\"\n",
    "    if data_path.exists() and data_path.stat().st_size > 0:\n",
    "        data = json.loads(data_path.read_text())\n",
    "        return data['variant_asins']\n",
    "    try:\n",
    "        data = parse_product_page(path.read_text())\n",
    "        data_path.write_text(json.dumps(data, indent=2))\n",
    "        return data['variant_asins']\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to parse {path}: {e}\")\n",
    "        raise e\n",
    "        \n",
    "\n",
    "asin_list = set(asin_list)\n",
    "to_search = deepcopy(asin_list)\n",
    "\n",
    "with mp.Pool() as pool:\n",
    "    print(f\"Evaluating {len(to_search)} products\")\n",
    "    files = pool.map(download_product_page, to_search)\n",
    "    files = [f for f in files if f]\n",
    "    variants = pool.map(parse_path, files)\n",
    "    variant_asins = set(chain.from_iterable(variants))\n",
    "    to_search = variant_asins - asin_list\n",
    "    asin_list |= variant_asins\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 17 products\n"
     ]
    }
   ],
   "source": [
    "with mp.Pool() as pool:\n",
    "    print(f\"Evaluating {len(to_search)} products\")\n",
    "    files = pool.map(download_product_page, to_search)\n",
    "    files = [f for f in files if f]\n",
    "    variants = pool.map(parse_path, files)\n",
    "    variant_asins = set(chain.from_iterable(variants))\n",
    "    to_search = variant_asins - asin_list\n",
    "    asin_list |= variant_asins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to parse pages/B08R9CLM5Y.html: [Errno 2] No such file or directory: 'data/B08R9CLM5Y.json'Failed to parse pages/B0BPHLTM3D.html: [Errno 2] No such file or directory: 'data/B0BPHLTM3D.json'Failed to parse pages/B092HVK7GB.html: [Errno 2] No such file or directory: 'data/B092HVK7GB.json'Failed to parse pages/B0CPP49XFT.html: [Errno 2] No such file or directory: 'data/B0CPP49XFT.json'\n",
      "Failed to parse pages/B0BS3QPYXW.html: [Errno 2] No such file or directory: 'data/B0BS3QPYXW.json'\n",
      "\n",
      "Failed to parse pages/B08F5L6NLT.html: [Errno 2] No such file or directory: 'data/B08F5L6NLT.json'\n",
      "Failed to parse pages/B0CNSSKQN8.html: [Errno 2] No such file or directory: 'data/B0CNSSKQN8.json'Failed to parse pages/B094V1VLRR.html: [Errno 2] No such file or directory: 'data/B094V1VLRR.json'\n",
      "\n",
      "\n",
      "\n",
      "Failed to parse pages/B0BGXZV6LH.html: [Errno 2] No such file or directory: 'data/B0BGXZV6LH.json'\n",
      "Failed to parse pages/B08BYFYCLW.html: [Errno 2] No such file or directory: 'data/B08BYFYCLW.json'\n",
      "Failed to parse pages/B08ZYM1NYQ.html: [Errno 2] No such file or directory: 'data/B08ZYM1NYQ.json'\n",
      "Failed to parse pages/B08S6VRK1Q.html: [Errno 2] No such file or directory: 'data/B08S6VRK1Q.json'\n",
      "Failed to parse pages/B0CNP3KDB6.html: [Errno 2] No such file or directory: 'data/B0CNP3KDB6.json'\n",
      "Failed to parse pages/B0CHY8FK1V.html: [Errno 2] No such file or directory: 'data/B0CHY8FK1V.json'\n",
      "Failed to parse pages/B0CQW9R9SD.html: [Errno 2] No such file or directory: 'data/B0CQW9R9SD.json'\n",
      "Failed to parse pages/B09JG432FZ.html: [Errno 2] No such file or directory: 'data/B09JG432FZ.json'\n",
      "Failed to parse pages/B09TY84HRN.html: [Errno 2] No such file or directory: 'data/B09TY84HRN.json'\n",
      "Failed to parse pages/B08DTTC695.html: [Errno 2] No such file or directory: 'data/B08DTTC695.json'\n",
      "Failed to parse pages/B0CNSQ1YBT.html: [Errno 2] No such file or directory: 'data/B0CNSQ1YBT.json'\n",
      "Failed to parse pages/B08BLDL2VF.html: [Errno 2] No such file or directory: 'data/B08BLDL2VF.json'Failed to parse pages/B08BLF3FB3.html: [Errno 2] No such file or directory: 'data/B08BLF3FB3.json'Failed to parse pages/B07DPK893W.html: [Errno 2] No such file or directory: 'data/B07DPK893W.json'\n",
      "\n",
      "\n",
      "Failed to parse pages/B0C4S3STX6.html: [Errno 2] No such file or directory: 'data/B0C4S3STX6.json'\n",
      "Failed to parse pages/B0BW3R41CJ.html: [Errno 2] No such file or directory: 'data/B0BW3R41CJ.json'\n",
      "Failed to parse pages/B08RCZP981.html: [Errno 2] No such file or directory: 'data/B08RCZP981.json'Failed to parse pages/B08NCHHF25.html: [Errno 2] No such file or directory: 'data/B08NCHHF25.json'\n",
      "\n",
      "Failed to parse pages/B0CPP2H9HH.html: [Errno 2] No such file or directory: 'data/B0CPP2H9HH.json'\n",
      "Failed to parse pages/B08BYG5WWS.html: [Errno 2] No such file or directory: 'data/B08BYG5WWS.json'\n",
      "Failed to parse pages/B09TY9QZVY.html: [Errno 2] No such file or directory: 'data/B09TY9QZVY.json'\n",
      "Failed to parse pages/B0B2NSDZWM.html: [Errno 2] No such file or directory: 'data/B0B2NSDZWM.json'\n",
      "Failed to parse pages/B0C85ZR488.html: [Errno 2] No such file or directory: 'data/B0C85ZR488.json'\n",
      "Failed to parse pages/B0BXX13M1J.html: [Errno 2] No such file or directory: 'data/B0BXX13M1J.json'\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/B08R9CLM5Y.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/parkerhancock/Library/Caches/pypoetry/virtualenvs/amazon-scrape-tnMfzeZV-py3.11/lib/python3.11/site-packages/multiprocess/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n                    ^^^^^^^^^^^^^^^^^^^\n  File \"/Users/parkerhancock/Library/Caches/pypoetry/virtualenvs/amazon-scrape-tnMfzeZV-py3.11/lib/python3.11/site-packages/multiprocess/pool.py\", line 48, in mapstar\n    return list(map(*args))\n           ^^^^^^^^^^^^^^^^\n  File \"/var/folders/d6/n1t1y02s0h5c4m0lmtww6fgw0000gn/T/ipykernel_70537/2421494976.py\", line 100, in parse_path\n    raise e\n  File \"/var/folders/d6/n1t1y02s0h5c4m0lmtww6fgw0000gn/T/ipykernel_70537/2421494976.py\", line 96, in parse_path\n    data_path.write_text(json.dumps(data))\n  File \"/Users/parkerhancock/.pyenv/versions/3.11.4/lib/python3.11/pathlib.py\", line 1078, in write_text\n    with self.open(mode='w', encoding=encoding, errors=errors, newline=newline) as f:\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/parkerhancock/.pyenv/versions/3.11.4/lib/python3.11/pathlib.py\", line 1044, in open\n    return io.open(self, mode, buffering, encoding, errors, newline)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFileNotFoundError: [Errno 2] No such file or directory: 'data/B08R9CLM5Y.json'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m html_files \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(html_dir\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*.html\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m mp\u001b[38;5;241m.\u001b[39mPool() \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparse_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhtml_files\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/amazon-scrape-tnMfzeZV-py3.11/lib/python3.11/site-packages/multiprocess/pool.py:367\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    363\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;124;03m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/amazon-scrape-tnMfzeZV-py3.11/lib/python3.11/site-packages/multiprocess/pool.py:774\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n\u001b[1;32m    773\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 774\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/B08R9CLM5Y.json'"
     ]
    }
   ],
   "source": [
    "html_files = list(html_dir.glob(\"*.html\"))\n",
    "\n",
    "with mp.Pool() as pool:\n",
    "    pool.map(parse_path, html_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scanning 833 asins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d6/n1t1y02s0h5c4m0lmtww6fgw0000gn/T/ipykernel_16054/3782952153.py:57: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  \"merchant_name\": merchant_el.text if merchant_el else None,\n",
      "/var/folders/d6/n1t1y02s0h5c4m0lmtww6fgw0000gn/T/ipykernel_16054/3782952153.py:58: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  \"merchant_url\": urljoin(product_base_url, merchant_el.get(\"href\")) if merchant_el else None,\n",
      "/var/folders/d6/n1t1y02s0h5c4m0lmtww6fgw0000gn/T/ipykernel_16054/3782952153.py:59: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  \"seller_id\": seller_id_re.search(merchant_el.get(\"href\")).group(1) if merchant_el else None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scanning 1495 asins\n",
      "downloading B0CD7Z2NXT\n",
      "downloading B0C1Z5WQ6W\n",
      "downloading B0CK2KGWJT\n",
      "downloading B0811Q9S36\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 128\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m to_search:\n\u001b[1;32m    125\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 128\u001b[0m \u001b[43mcrawl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweighted knitted blanket\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 121\u001b[0m, in \u001b[0;36mcrawl\u001b[0;34m(query)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscanning \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(to_search)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m asins\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 121\u001b[0m     variant_asins \u001b[38;5;241m=\u001b[39m \u001b[43mparse_asin_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_search\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m     to_search \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(variant_asins) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(asin_list)\n\u001b[1;32m    123\u001b[0m     asin_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(asin_list) \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mset\u001b[39m(variant_asins)\n",
      "Cell \u001b[0;32mIn[5], line 91\u001b[0m, in \u001b[0;36mparse_asin_list\u001b[0;34m(asin_list)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m asin \u001b[38;5;129;01min\u001b[39;00m asin_list:\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 91\u001b[0m         text \u001b[38;5;241m=\u001b[39m \u001b[43mdownload_product_page\u001b[49m\u001b[43m(\u001b[49m\u001b[43masin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m         data \u001b[38;5;241m=\u001b[39m parse_product_page(text)\n\u001b[1;32m     93\u001b[0m         data_path \u001b[38;5;241m=\u001b[39m data_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00masin\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[0;32mIn[5], line 81\u001b[0m, in \u001b[0;36mdownload_product_page\u001b[0;34m(asin)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdownloading\u001b[39m\u001b[38;5;124m\"\u001b[39m, asin)\n\u001b[1;32m     80\u001b[0m url \u001b[38;5;241m=\u001b[39m product_base_url \u001b[38;5;241m+\u001b[39m asin\n\u001b[0;32m---> 81\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43ms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[1;32m     83\u001b[0m out_path\u001b[38;5;241m.\u001b[39mwrite_text(response\u001b[38;5;241m.\u001b[39mtext)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/amazon-scrape-tnMfzeZV-py3.11/lib/python3.11/site-packages/requestium/requestium.py:128\u001b[0m, in \u001b[0;36mSession.get\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 128\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mSession\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_requests_url \u001b[38;5;241m=\u001b[39m resp\u001b[38;5;241m.\u001b[39murl\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m RequestiumResponse(resp)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/amazon-scrape-tnMfzeZV-py3.11/lib/python3.11/site-packages/requests/sessions.py:602\u001b[0m, in \u001b[0;36mSession.get\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[1;32m    595\u001b[0m \n\u001b[1;32m    596\u001b[0m \u001b[38;5;124;03m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;124;03m:param \\*\\*kwargs: Optional arguments that ``request`` takes.\u001b[39;00m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;124;03m:rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    601\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 602\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/amazon-scrape-tnMfzeZV-py3.11/lib/python3.11/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/amazon-scrape-tnMfzeZV-py3.11/lib/python3.11/site-packages/requests/sessions.py:747\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    744\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[0;32m--> 747\u001b[0m     \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\n\u001b[1;32m    749\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/amazon-scrape-tnMfzeZV-py3.11/lib/python3.11/site-packages/requests/models.py:899\u001b[0m, in \u001b[0;36mResponse.content\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    898\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 899\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_content(CONTENT_CHUNK_SIZE)) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content_consumed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;66;03m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[1;32m    903\u001b[0m \u001b[38;5;66;03m# since we exhausted the data.\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/amazon-scrape-tnMfzeZV-py3.11/lib/python3.11/site-packages/requests/models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    815\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 816\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    817\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    818\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/amazon-scrape-tnMfzeZV-py3.11/lib/python3.11/site-packages/urllib3/response.py:1040\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;124;03mA generator wrapper for the read() method. A call will block until\u001b[39;00m\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;124;03m``amt`` bytes have been read from the connection or until the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;124;03m    'content-encoding' header.\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunked \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupports_chunked_reads():\n\u001b[0;32m-> 1040\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_chunked(amt, decode_content\u001b[38;5;241m=\u001b[39mdecode_content)\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1042\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/amazon-scrape-tnMfzeZV-py3.11/lib/python3.11/site-packages/urllib3/response.py:1184\u001b[0m, in \u001b[0;36mHTTPResponse.read_chunked\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1183\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1184\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_chunk_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1185\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1186\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/amazon-scrape-tnMfzeZV-py3.11/lib/python3.11/site-packages/urllib3/response.py:1108\u001b[0m, in \u001b[0;36mHTTPResponse._update_chunk_length\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1108\u001b[0m line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline()  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[1;32m   1109\u001b[0m line \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1110\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/ssl.py:1278\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1275\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1276\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1277\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1279\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/ssl.py:1134\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1133\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1135\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def download_product_page(asin):\n",
    "    out_path = html_dir / f\"{asin}.html\"\n",
    "    if out_path.exists() and out_path.stat().st_size > 0:\n",
    "        return out_path.read_text()\n",
    "    print(\"downloading\", asin)\n",
    "    url = product_base_url + asin\n",
    "    response = s.get(url)\n",
    "    response.raise_for_status()\n",
    "    out_path.write_text(response.text)\n",
    "    return out_path.read_text()\n",
    "    \n",
    "def parse_asin_list(asin_list):\n",
    "    variant_asin_list = list()\n",
    "    \n",
    "    for asin in asin_list:\n",
    "        try:\n",
    "            text = download_product_page(asin)\n",
    "            data = parse_product_page(text)\n",
    "            data_path = data_dir / f\"{asin}.json\"\n",
    "            data_path.write_text(json.dumps(data, indent=2))\n",
    "            image_extension = data[\"cover_image\"].split(\".\")[-1]\n",
    "            image_path = image_dir / f\"{asin}.{image_extension}\"\n",
    "            if not image_path.exists():\n",
    "                image_response = s.get(data[\"cover_image\"])\n",
    "                image_response.raise_for_status()\n",
    "                image_path.write_bytes(image_response.content)\n",
    "            variant_asin_list.extend(data[\"variant_asins\"])\n",
    "        except Exception as e:\n",
    "            print(f\"failed to process {asin}: {e}\")\n",
    "            raise e\n",
    "    return variant_asin_list\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "def crawl(query):\n",
    "    #s.driver.get(\"https://www.amazon.com\")\n",
    "    #search_box = s.driver.find_element(By.ID, \"twotabsearchtextbox\")\n",
    "    #search_box.send_keys(query)\n",
    "    #search_box.submit()\n",
    "    #asin_list = collect_asin_from_search_results()\n",
    "    #s.transfer_driver_cookies_to_session()\n",
    "    asin_list = [p.name.split(\".\")[0] for p in html_dir.glob(\"*.html\")]\n",
    "    to_search = set(deepcopy(asin_list))\n",
    "    while True:\n",
    "        print(f\"scanning {len(to_search)} asins\")\n",
    "        variant_asins = parse_asin_list(to_search)\n",
    "        to_search = set(variant_asins) - set(asin_list)\n",
    "        asin_list = set(asin_list) | set(variant_asins)\n",
    "        if not to_search:\n",
    "            break\n",
    "        \n",
    "        \n",
    "crawl(\"weighted knitted blanket\")\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "s.transfer_driver_cookies_to_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for asin in asin_list:\n",
    "    download_product_page(asin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lxml.etree as ET\n",
    "response = s.get(base_url + asin_list[0])\n",
    "response.raise_for_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'product_title': 'Chenille Chunky Knit Blanket Throw （40×50 Inch）, Handmade Warm & Cozy Blanket Couch, Bed, Home Decor, Soft Breathable Fleece Banket, Christmas Thick and Giant Yarn Throws, Cream',\n",
       " 'product_details': {'material': 'Chenille',\n",
       "  'color': 'Cream',\n",
       "  'brand': 'Maetoow',\n",
       "  'special_feature': 'Skin Friendly',\n",
       "  'style': 'Modern',\n",
       "  'blanket_form': 'Throw Blanket',\n",
       "  'age_range_(description)': 'kids, adults',\n",
       "  'product_dimensions': '50\"L x 40\"W',\n",
       "  'theme': 'Space',\n",
       "  'pattern': 'Solid',\n",
       "  'recommended_uses_for_product': 'household',\n",
       "  'seasons': 'Winter',\n",
       "  'weave_type': 'Chunky Knit',\n",
       "  'product_care_instructions': 'Machine Wash',\n",
       "  'size': \"40''x50''\",\n",
       "  'fabric_type': '100% Chenille',\n",
       "  'unit_count': '1 Count',\n",
       "  'number_of_items': '5',\n",
       "  'fabric_warmth_description': 'Medium/Heavyweight',\n",
       "  'sport': 'Camping',\n",
       "  'model_name': 'small',\n",
       "  'item_weight': '3.74 pounds',\n",
       "  'manufacturer': 'wanhong',\n",
       "  'asin': 'B0B766SCS5',\n",
       "  'country_of_origin': 'China',\n",
       "  'item_model_number': 'small',\n",
       "  'customer_reviews': '',\n",
       "  'best_sellers_rank': '',\n",
       "  'batteries_required': 'No'},\n",
       " 'variant_asins': ['B0CF25J81Y',\n",
       "  'B0C6JRY71S',\n",
       "  'B09NY6WR13',\n",
       "  'B0B766SCS5',\n",
       "  'B0B9W6FKSY',\n",
       "  'B0B767T429',\n",
       "  'B09NY57ZDC',\n",
       "  'B0B9WPB1LM',\n",
       "  'B0B7678SSN',\n",
       "  'B0BJ253N7B',\n",
       "  'B0B9WSPL8T',\n",
       "  'B0BN1H7BN2',\n",
       "  'B0B9X8TMJH',\n",
       "  'B0BJ25JVZT',\n",
       "  'B0BN1KB54T',\n",
       "  'B0B766QHHH',\n",
       "  'B0CJV285JB',\n",
       "  'B0B766SCS5',\n",
       "  'B09H3CWWQD',\n",
       "  'B0C4H21XYT'],\n",
       " 'cover_image': 'https://m.media-amazon.com/images/I/9151yp5pDBL.__AC_SX300_SY300_QL70_ML2_.jpg',\n",
       " 'price': '$49.99',\n",
       " 'merchant_name': 'Maetoow',\n",
       " 'merchant_url': '/gp/help/seller/at-a-glance.html/ref=dp_merchant_link?ie=UTF8&seller=A2RQ4D8CAUVFXV&asin=B0B766SCS5&ref_=dp_merchant_link&isAmazonFulfilled=1',\n",
       " 'seller_id': 'A2RQ4D8CAUVFXV'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "    \n",
    "parse_product_page(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B08SQFBQV2',\n",
       " 'B0CJPPZKJC',\n",
       " 'B09XHC18H9',\n",
       " 'B0B4VW9CZ1',\n",
       " 'B09YS1214X',\n",
       " 'B0CFQCT46L',\n",
       " 'B0C6MQ2N3S',\n",
       " 'B0BBZFBYJL',\n",
       " 'B07SRY7GBK',\n",
       " 'B0C1FBJGFR',\n",
       " 'B096FQR7NP',\n",
       " 'B09BC4YFJM',\n",
       " 'B0BPSDDNHQ',\n",
       " 'B0CGJF55C7',\n",
       " 'B09QQ7CZY4',\n",
       " 'B0B5GFQ9HW',\n",
       " 'B0C4ZYX8WP',\n",
       " 'B0B7WDGG2C',\n",
       " 'B08FMFTVXC',\n",
       " 'B0C9KW6THW',\n",
       " 'B0CPF6G6FN',\n",
       " 'B0B38YC8CK',\n",
       " 'B0811Q54RQ',\n",
       " 'B09D7J26XF',\n",
       " 'B08BYGK4HH',\n",
       " 'B0C4S7R8PN',\n",
       " 'B0CF1TDCPK',\n",
       " 'B0CCVJFG7Z',\n",
       " 'B0CKT88DDV',\n",
       " 'B0CJPQ7CVQ',\n",
       " 'B0CGV9R2Q4',\n",
       " 'B0CGWJT9PC',\n",
       " 'B0CJPRG6GL',\n",
       " 'B09T3CTKP2',\n",
       " 'B092HVF7FT',\n",
       " 'B096FPJCF2',\n",
       " 'B0BR6LBH65',\n",
       " 'B0BR728TB6',\n",
       " 'B0CNV9TLLW',\n",
       " 'B0B2NSM1HK',\n",
       " 'B099FKPCDP',\n",
       " 'B08T6Q716K',\n",
       " 'B0CF1SV1RP',\n",
       " 'B082XYS6HB',\n",
       " 'B093Q6H1XJ',\n",
       " 'B09514WX62',\n",
       " 'B0CB48XLH3',\n",
       " 'B0CJPR48QB',\n",
       " 'B0CBRDTC6P',\n",
       " 'B0B61WYSYK',\n",
       " 'B099FLVTLL',\n",
       " 'B08DNQLXTT',\n",
       " 'B0B2NTWD7Q',\n",
       " 'B0BW3QQJK4',\n",
       " 'B07MW2YFQ7',\n",
       " 'B0CJPQCKXY',\n",
       " 'B0C2PN2SBD',\n",
       " 'B0CM435Y91',\n",
       " 'B0C4PHZF49',\n",
       " 'B0C1BTZP93',\n",
       " 'B08BL8BJ11',\n",
       " 'B07TBJ1ZG6',\n",
       " 'B0BFH6ZW3S',\n",
       " 'B0CF5KZLGX',\n",
       " 'B0BZSYMVR9',\n",
       " 'B0B2NT2NMZ',\n",
       " 'B0BB2H68TT',\n",
       " 'B08VJ2Q1YB',\n",
       " 'B08CH9JZRL',\n",
       " 'B0CCR1ZV15',\n",
       " 'B0CDGVRZXR',\n",
       " 'B0CJFWKHD7',\n",
       " 'B0B766SCS5',\n",
       " 'B0CLY3TSZN',\n",
       " 'B0C26XSMC7',\n",
       " 'B0CCSNSG3G',\n",
       " 'B07C1DGDQ5',\n",
       " 'B0C2PNH94L',\n",
       " 'B0B2NSQ6HY',\n",
       " 'B09CLDZ7CJ',\n",
       " 'B0BZ8K1YJ6',\n",
       " 'B099FM2J75',\n",
       " 'B0CJV25VWT',\n",
       " 'B0829TVV9H',\n",
       " 'B0B185S2N5',\n",
       " 'B0C1PDWRR7',\n",
       " 'B0C2Q385G6',\n",
       " 'B0CGVQPPYY',\n",
       " 'B0C1ZFN2TF',\n",
       " 'B09P3Q7YFP']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asin_list = [p.stem for p in workdir.glob(\"*.html\")]\n",
    "asin_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amazon-scrape-tnMfzeZV-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
